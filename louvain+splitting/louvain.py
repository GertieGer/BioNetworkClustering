# Tested on NetworkX 1.11
from communitytracker import CommunityTracker

import networkx as nx

from collections import defaultdict
import random


class Louvain:

    def __init__(self, G, verbose=False, randomized=False, splitting_func=None, remerge=False):
        # SETTINGS
        self.verbose = verbose
        self.randomized = randomized
        # Create helper to track network statistics.
        # We use the coarse_grain_graph in the iterations.
        self.tracker = CommunityTracker()
        self.original_graph = G
        self.coarse_grain_graph = G
        # self.community_history keeps track of the community maps
        # from each iteration.
        self.community_history = []
        self.iteration_count = 0
        self.finished = False
        # Final community map and list of communities created at end.
        self.community_map = None
        self.communities = None
        self.splitting_func = splitting_func
        self.remerge = remerge
        self.pre_split_communities = None

    def run(self):
        """Runs the iterations of the Louvain method until finished then
        generates the final community map.
        """
        i = 0
        while not self.finished:
            self.iterate()
            i+=1
        if self.verbose:
            print("Finished in {} iterations".format(self.iteration_count))
        self.community_map = self.generate_community_map(
            self.community_history)
        self.communities = self.invert_community_map(self.community_map)
        print("num of iterations: ", i)

    def iterate(self):
        """Performs one iteration of the Louvain method on the current graph G.

        For each node we move it to a neighbouring community which causes the
        greatest increase in modularity (if there is no such positive change we
        leave it where it is). We continue this until no more moves can be done
        so we have reached a local modularity optimum.

        We then create a new coarse grained graph where each node represents a
        community for the next iteration.
        """
        self.iteration_count += 1
        if self.verbose:
            print("Iteration: ", self.iteration_count)
        # modified if we have made at least one change overall.
        # improved if we have made at least one change in the current pass.
        modified = False
        improved = True
        G = self.coarse_grain_graph
        if self.remerge == True:
            self.tracker.initialize_network_statistics(G,pre_split_communities)
        else:
            self.tracker.initialize_network_statistics(G)

        community_map = self.tracker.node_to_community_map
        # if self.pre_split_communities!=None:
        #     self.remerge_sub_communities(community_map)

        while improved:
            improved = False

            nodes = G.nodes()
            if self.randomized:
                nodes = list(G.nodes())
                random.seed()
                random.shuffle(nodes)

            for node in nodes:
                best_delta_Q = 0.0
                old_community = community_map[node]
                new_community = old_community
                neighbour_communities = self.get_neighbour_communities(
                    G, node, community_map)
                # Isolate the current node and find the best neighbouring
                # community (including checking the original).
                old_incident_weight = neighbour_communities.get(
                    old_community, 0)
                self.tracker.remove(node, old_community, old_incident_weight)
                for community, incident_wt in neighbour_communities.items():
                    delta_Q = self.calculate_delta_Q(
                        G, node, community, incident_wt)
                    if delta_Q > best_delta_Q:
                        best_delta_Q = delta_Q
                        new_community = community

                # Move to the best community and check if we actually improved.
                new_incident_weight = neighbour_communities[new_community]
                self.tracker.insert(node, new_community, new_incident_weight)
                if self.verbose:
                    message = "Moved node {} from community {} to community {}"
                    print(message.format(node, old_community, new_community))

                if new_community != old_community:
                    improved = True
                    modified = True

        if modified:
            if self.splitting_func != None:
                # split community_map 
                self.communities = self.invert_community_map(community_map)
                self.split_communities(self.communities, community_map) # makes changes in community_map
            self.relabel_community_map(community_map)
            self.community_history.append(community_map)
            self.coarse_grain_graph = self.generate_coarse_grain_graph(
                G, community_map)
        else:
            # We didn't modify any nodes so we are finished.
            self.finished = True

    def split_communities(self, communities, community_map):
        """by us:
        Applies a divisive clustering algorithm on the subgraph defined by each community.
        this may cause the community to sub communities.
        """
        self.pre_split_communities = {}
        max_community = 0
        for i, community in enumerate(communities):
            subgraph = (self.original_graph).subgraph(community)
            if len(subgraph.nodes()) == 0 :
                self.pre_split_communities[i] = i
                max_community+=1
                continue
            sub_community_map = self.splitting_func(subgraph)
            if len(sub_community_map) == len(sub_community_map.values()):
                # not useful, ignore
                for node in sub_community_map:
                    new_community = max_community + 0
                    community_map[node] = new_community
                    self.pre_split_communities[new_community] = i
            else:
                for node, sub in sub_community_map.items():
                    new_community = max_community + sub
                    community_map[node] = new_community
                    self.pre_split_communities[new_community] = i

            max_community += len(sub_community_map)

    def get_neighbour_communities(self, G, node, community_map):
        """Returns a dictionary with the neighbouring communities as keys and
        incident edge weights between node and the community as values.
        """
        neighbour_communities = defaultdict(int)
        for neighbour in G[node]:
            if neighbour != node:
                neighbour_community = community_map[neighbour]
                w = G[node][neighbour].get("weight", 1)
                neighbour_communities[neighbour_community] += w
        return neighbour_communities

    def calculate_delta_Q(self, G, node, community, incident_weight):
        """Calculate change in modularity from adding isolated node to
        community."""
        # Sum of the weights of the links incident to nodes in C.
        sigma_tot = self.tracker.community_degrees[community]
        # Sum of the weights of the links incident to node i.
        k_i = self.tracker.degrees[node]
        # Sum of the weights of the links from i to nodes in C.
        k_i_in = incident_weight
        # Sum of the weights of all the links in the network.
        m = self.tracker.m

        delta_Q = 2 * k_i_in - sigma_tot * k_i / m
        return delta_Q

    def generate_coarse_grain_graph(self, G, community_map):
        """Generates new coarse grain graph with each community as a single
        node.

        Weights between nodes are the sum of all weights between respective
        communities and self loops are added for the weights of he internal
        edges.
        """
        new_graph = nx.Graph()
        # Create nodes for each community.
        for community in set(community_map.values()):
            new_graph.add_node(community)
        # Create the combined edges from the individual old edges.
        for u, v, w in G.edges(data="weight", default=1):
            c1 = community_map[u]
            c2 = community_map[v]
            new_weight = w
            if new_graph.has_edge(c1, c2):
                new_weight += new_graph[c1][c2].get("weight", 1)
            new_graph.add_edge(c1, c2, weight=new_weight)
        return new_graph

    def relabel_community_map(self, community_map):
        """Relabels communities to be from 0 to n."""
        community_labels = set(community_map.values())
        new_pre_split_communities = {}
        relabelled_communities = {j: i for i, j in enumerate(community_labels)}
        for node in community_map:
            community = community_map[node]
            community_map[node] = relabelled_communities[community]
            if self.pre_split_communities!=None:
                new_pre_split_communities[relabelled_communities[community]] = \
                    self.pre_split_communities[community]
        
        if self.pre_split_communities!=None:
            self.pre_split_communities = new_pre_split_communities

    def invert_community_map(self, community_map):
        """Inverts a community map from nodes to communities to a list of
        lists of nodes where each list of nodes represents one community.
        """
        inverted_community_map = defaultdict(list)
        for node in community_map:
            inverted_community_map[community_map[node]].append(node)
        return list(inverted_community_map.values())

    def generate_community_map(self, community_history):
        """Builds the final community map using the history of iterations."""
        community_map = {node: node for node in self.original_graph}
        for node in community_map:
            for iteration in community_history:
                # Follow iterations to find final community of node.
                community_map[node] = iteration[community_map[node]]
        return community_map


def detect_communities(G, verbose=False, randomized=False, splitting_func=None, remerge=False):
    """Returns the detected communities as a list of lists of nodes
    representing each community.

    Uses the Louvain heuristic from:
        Blondel, V.D. et al. Fast unfolding of communities in
    large networks. J. Stat. Mech 10008, 1 - 12(2008).
    """
    louvain = Louvain(G, verbose=verbose, randomized=randomized, splitting_func=splitting_func, remerge=remerge)
    louvain.run()
    return louvain.communities
